---
title: BenchDatasetEvaluator
createTime: 2025/10/09 17:09:04
permalink: /zh/api/operators/core_text/eval/benchdatasetevaluator/
---

## ğŸ“˜ æ¦‚è¿° [BenchDatasetEvaluator](https://github.com/OpenDCAI/DataFlow/blob/main/dataflow/operators/evaluator/bench_dataset_evaluator.py)
è¯¥ç®—å­ç”¨äºå¯¹æ¯”é¢„æµ‹ç­”æ¡ˆä¸æ ‡å‡†ç­”æ¡ˆçš„åŒ¹é…åº¦ï¼Œæ”¯æŒä¸¤ç§è¯„ä¼°æ¨¡å¼ï¼š

1.  å­—ç¬¦ä¸²åŒ¹é…ï¼ˆmatchï¼‰ï¼šä½¿ç”¨æ•°å­¦éªŒè¯æ–¹æ³•æ¯”è¾ƒç­”æ¡ˆï¼Œé€‚ç”¨äºæœ‰æ˜ç¡®ç­”æ¡ˆçš„é—®é¢˜
2.  è¯­ä¹‰åŒ¹é…ï¼ˆsemanticï¼‰ï¼šä½¿ç”¨LLMè¯„ä¼°ç­”æ¡ˆçš„è¯­ä¹‰ç›¸ä¼¼åº¦ï¼Œé€‚ç”¨äºå¼€æ”¾æ€§é—®é¢˜

è¾“å…¥å‚æ•°ï¼š
-   input\_test\_answer\_keyï¼šé¢„æµ‹ç­”æ¡ˆå­—æ®µå
-   input\_gt\_answer\_keyï¼šæ ‡å‡†ç­”æ¡ˆå­—æ®µå
-   input\_question\_keyï¼šé—®é¢˜å­—æ®µåï¼ˆè¯­ä¹‰åŒ¹é…æ¨¡å¼ä¸‹å¿…éœ€ï¼‰
-   compare\_methodï¼šæ¯”è¾ƒæ–¹æ³•ï¼ˆmatch/semanticï¼‰

è¾“å‡ºå‚æ•°ï¼š
-   answer\_match\_resultï¼šåŒ¹é…ç»“æœï¼ˆTrue/Falseï¼‰
-   ç»Ÿè®¡ç»“æœå°†ä¿å­˜åˆ°æŒ‡å®šçš„eval\_result\_pathè·¯å¾„

## \_\_init\_\_å‡½æ•°

```python
def __init__(self,
            eval_result_path: str = None,
            compare_method: Literal["match", "semantic"] = "match",
            system_prompt: str = "You are a helpful assistant specialized in evaluating answer correctness.",
            llm_serving: LLMServingABC = None,
            prompt_template = None
            ):
```

### initå‚æ•°è¯´æ˜

| å‚æ•°å | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
| :--- | :--- | :--- | :--- |
| **eval\_result\_path** | str | None | è¯„ä¼°ç»“æœçš„ä¿å­˜è·¯å¾„ã€‚è‹¥ä¸æŒ‡å®šï¼Œåˆ™è‡ªåŠ¨ç”Ÿæˆå¸¦æœ‰æ—¶é—´æˆ³çš„æ–‡ä»¶åã€‚ |
| **compare\_method** | Literal["match", "semantic"] | "match" | è¯„ä¼°æ–¹æ³•ï¼Œ'match'è¡¨ç¤ºå­—ç¬¦ä¸²ç²¾ç¡®åŒ¹é…ï¼ˆé€‚ç”¨äºæ•°å­¦ç­‰ï¼‰ï¼Œ'semantic'è¡¨ç¤ºä½¿ç”¨LLMè¿›è¡Œè¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…ã€‚ |
| **system\_prompt** | str | "You are a helpful assistant specialized in evaluating answer correctness." | å½“ä½¿ç”¨'semantic'è¯„ä¼°æ–¹æ³•æ—¶ï¼Œä¼ é€’ç»™LLMçš„ç³»ç»Ÿæç¤ºè¯ã€‚ |
| **llm\_serving** | LLMServingABC | None | å¤§è¯­è¨€æ¨¡å‹æœåŠ¡å®ä¾‹ï¼Œå½“ `compare_method` ä¸º 'semantic' æ—¶å¿…éœ€ã€‚ |
| **prompt\_template** | PromptABC | None | æç¤ºè¯æ¨¡æ¿å¯¹è±¡ï¼Œå½“ `compare_method` ä¸º 'semantic' æ—¶ä½¿ç”¨ã€‚è‹¥ä¸æŒ‡å®šï¼Œåˆ™é»˜è®¤ä¸º `AnswerJudgePrompt`ã€‚ |

### Promptæ¨¡æ¿è¯´æ˜

## runå‡½æ•°

```python
def run(
        self,
        storage:DataFlowStorage,
        input_test_answer_key: str = "generated_cot",
        input_gt_answer_key: str = "golden_answer",
        input_question_key: str = None,
        ) -> list:
```

#### å‚æ•°

| åç§° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
| :--- | :--- | :--- | :--- |
| **storage** | DataFlowStorage | å¿…éœ€ | æ•°æ®æµå­˜å‚¨å®ä¾‹ï¼Œè´Ÿè´£è¯»å–ä¸å†™å…¥æ•°æ®ã€‚ |
| **input\_test\_answer\_key** | str | "generated\_cot" | è¾“å…¥åˆ—åï¼Œå¯¹åº”å¾…è¯„ä¼°çš„ç­”æ¡ˆå­—æ®µã€‚ |
| **input\_gt\_answer\_key** | str | "golden\_answer" | è¾“å…¥åˆ—åï¼Œå¯¹åº”æ ‡å‡†ç­”æ¡ˆï¼ˆground truthï¼‰å­—æ®µã€‚ |
| **input\_question\_key** | str | None | è¾“å…¥åˆ—åï¼Œå¯¹åº”é—®é¢˜å­—æ®µã€‚å½“ `compare_method` ä¸º'semantic'æ—¶å¿…éœ€ã€‚ |

## ğŸ§  ç¤ºä¾‹ç”¨æ³•
