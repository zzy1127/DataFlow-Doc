---
title: çŸ¥è¯†åº“æ¸…æ´—æµæ°´çº¿
icon: fa6-regular:bookmark
createTime: 2025/06/16 13:08:42
permalink: /zh/guide/kbcpipeline/
---
# çŸ¥è¯†åº“æ¸…æ´—åŠQAåˆæˆæµæ°´çº¿

## 1. æ¦‚è¿°

çŸ¥è¯†åº“æ¸…æ´—æµæ°´çº¿çš„æ ¸å¿ƒç›®æ ‡æ˜¯å¯¹äºç”¨æˆ·æä¾›çš„æ ¼å¼å¼‚æ„ã€ä¿¡æ¯å™ªå£°é«˜çš„åŸå§‹æ–‡æ¡£ï¼Œæä¾›**ç«¯åˆ°ç«¯çš„**ä¿¡æ¯æå–ã€è§„èŒƒåŒ–ä»¥åŠå¿…è¦å…ƒä¿¡æ¯çš„ç”ŸæˆæœåŠ¡ã€‚è¿™æ ·æå–å‡ºçš„æ•°æ®å¯ä»¥ç›´æ¥ç”¨äºRAGã€é¢„è®­ç»ƒï¼Œä»¥åŠä¼—å¤šå¤§æ¨¡å‹ä¸‹æ¸¸ä»»åŠ¡ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæµæ°´çº¿é€šè¿‡æ»‘åŠ¨çª—å£çš„æ–¹å¼ï¼ŒæŠŠæ¸…æ´—å¥½çš„çŸ¥è¯†è½¬åŒ–æˆä¸€ç»„Multi-Hop QAã€‚æ ¹æ®[MIRIAD](https://github.com/eth-medical-ai-lab/MIRIAD)çš„å®éªŒï¼Œè¿™ç§QAæ ¼å¼çš„çŸ¥è¯†æ›´æœ‰åˆ©äºRAGå‡†ç¡®æ¨ç†ã€‚

çŸ¥è¯†åº“æ¸…æ´—æ”¯æŒçš„æ–‡ä»¶æ ¼å¼åŒ…æ‹¬**PDF, Markdown, HTMLä»¥åŠçˆ¬å–URL**å¯¹åº”çš„ç½‘é¡µä¿¡æ¯ã€‚

æµæ°´çº¿çš„ä¸»è¦æµç¨‹åŒ…æ‹¬ï¼š

1. ä¿¡æ¯æå–ï¼šå€ŸåŠ©[MinerU](https://github.com/opendatalab/MinerU), [trafilatura](https://github.com/adbar/trafilatura)ç­‰å·¥å…·ä»åŸå§‹æ–‡æ¡£ä¸­æå–æ–‡æœ¬ä¿¡æ¯ã€‚
2. æ–‡æœ¬åˆ†æ®µï¼šå€ŸåŠ©[chonkie](https://github.com/chonkie-inc/chonkie)å°†æ–‡æœ¬åˆ‡åˆ†æˆç‰‡æ®µï¼Œæ”¯æŒé€šè¿‡Tokenï¼Œå­—ç¬¦ï¼Œå¥å­ç­‰åˆ†æ®µæ–¹å¼ã€‚
3. çŸ¥è¯†æ¸…æ´—ï¼šä»å†—ä½™æ ‡ç­¾ï¼Œæ ¼å¼é”™è¯¯ï¼Œå±è”½éšç§ä¿¡æ¯å’Œè¿è§„ä¿¡æ¯ç­‰è§’åº¦å¯¹åŸå§‹æ–‡æœ¬ä¿¡æ¯è¿›è¡Œæ¸…æ´—ï¼Œä½¿æ–‡æœ¬ä¿¡æ¯æ›´åŠ æ¸…æ´å¯ç”¨ã€‚
4. QAæ„å»ºï¼šåˆ©ç”¨é•¿åº¦ä¸ºä¸‰ä¸ªå¥å­çš„æ»‘åŠ¨çª—å£ï¼Œå°†æ¸…æ´—å¥½çš„çŸ¥è¯†åº“è½¬å†™æˆä¸€ç³»åˆ—éœ€è¦å¤šæ­¥æ¨ç†çš„QAï¼Œæ›´æœ‰åˆ©äºRAGå‡†ç¡®æ¨ç†ã€‚

## 2. æµæ°´çº¿è®¾è®¡

### 1. ä¿¡æ¯æå–

æµæ°´çº¿ç¬¬ä¸€æ­¥æ˜¯é€šè¿‡FileOrURLToMarkdownConverterä»ç”¨æˆ·åŸå§‹æ–‡æ¡£æˆ–URLä¸­æå–æ–‡æœ¬çŸ¥è¯†ã€‚æ­¤æ­¥éª¤è‡³å…³é‡è¦ï¼Œå®ƒå°†å„ç§æ ¼å¼çš„åŸå§‹æ–‡æ¡£æå–æˆç»Ÿä¸€çš„markdownæ ¼å¼æ–‡æœ¬ï¼Œæ–¹ä¾¿åç»­æ¸…æ´—æ­¥éª¤è¿›è¡Œã€‚

> *ç”±äº `MinerU` ä¸»è¦åŸºäº `SGLang` è¿›è¡Œéƒ¨ç½²ï¼Œ`open-dataflow[minerU]` ç¯å¢ƒä¸»è¦åŸºäº `Dataflow[SGLang]` è¿›è¡Œå¤„ç†ï¼Œæ–‡æœªæœ‰åŸºäº `Dataflow[vllm]` çš„å¤„ç†æ•™ç¨‹ã€‚*

```shell
conda create -n dataflow python=3.10
conda activate dataflow
git clone https://github.com/OpenDCAI/DataFlow.git
cd DataFlow
pip install -e .[mineru]
```

æœ¬ç³»ç»Ÿä¸­PDFæ–‡ä»¶çš„æå–åŸºäº[MinerU](https://github.com/opendatalab/MinerU),éœ€è¿›è¡Œé¢å¤–é…ç½®ï¼Œç”¨æˆ·å¯é€šè¿‡å¦‚ä¸‹æ–¹å¼é…ç½®ã€‚

> #### ä½¿ç”¨æœ¬åœ°æ¨¡å‹
>
> ä¸ºäº†åœ¨æœ¬åœ°è¿è¡Œ `MinerU` æ¨¡å‹ï¼Œæ‚¨éœ€è¦å…ˆå°†å®ƒä»¬ä¸‹è½½åˆ°æœ¬åœ°å­˜å‚¨ã€‚`MinerU` æä¾›äº†ä¸€ä¸ªäº¤äº’å¼å‘½ä»¤è¡Œå·¥å…·æ¥ç®€åŒ–æ­¤è¿‡ç¨‹ã€‚
>
> #### 1. ä¸‹è½½å·¥å…·æŒ‡å¼•ï¼š
>
> æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹æ¨¡å‹ä¸‹è½½å·¥å…·çš„å¸®åŠ©ä¿¡æ¯ï¼š
>
> ```bash
> mineru-models-download --help
> ```
>
> #### 2. å¯åŠ¨æ¨¡å‹ä¸‹è½½ï¼š
>
> æ‰§è¡Œä»¥ä¸‹å‘½ä»¤å¼€å§‹ä¸‹è½½è¿‡ç¨‹ï¼š
>
> ```bash
> mineru-models-download
> ```
>
> åœ¨ä¸‹è½½è¿‡ç¨‹ä¸­ï¼Œæ‚¨å°†çœ‹åˆ°ä»¥ä¸‹äº¤äº’å¼æç¤ºï¼š
>
> * **é€‰æ‹©æ¨¡å‹ä¸‹è½½æº**ï¼š
>
>   ```bash
>   Please select the model download source: (huggingface, modelscope) [huggingface]:
>   ```
>
>   *å»ºè®®æ‚¨é€‰æ‹© `modelscope` ä½œä¸ºä¸‹è½½æºï¼Œä»¥è·å–æ›´ä¼˜çš„ä¸‹è½½ä½“éªŒã€‚*
> * **é€‰æ‹©`MinerU` ç‰ˆæœ¬**ï¼š
>
>   `MinerU1`ä¸º`pipeline`å½¢å¼è§£æï¼Œé€Ÿåº¦è¾ƒæ…¢ï¼Œæ˜¾å­˜è¦æ±‚ä½ã€‚
>   `MinerU2`ä¸º`vlm`å½¢å¼è§£æï¼Œé€Ÿåº¦è¾ƒå¿«ï¼Œæ˜¾å­˜è¦æ±‚é«˜ã€‚
>
>   ç”¨æˆ·å¯ä»¥æŒ‰éœ€è‡ªç”±é€‰æ‹©æƒ³ä½¿ç”¨çš„MinerUè§£æç‰ˆæœ¬ç„¶åä¸‹è½½åˆ°æœ¬åœ°ã€‚
>
>   <table>
>     <tbody>
>       <tr>
>         <td>è§£æåç«¯</td>
>         <td>pipeline</td>
>         <td>vlm-sglang</td>
>       </tr>
>       <tr>
>         <td>æ“ä½œç³»ç»Ÿ</td>
>         <td>Linux / Windows / macOS</td>
>         <td>Linux / Windows (via WSL2)</td>
>       </tr>
>       <tr>
>         <td>CPUæ¨ç†æ”¯æŒ</td>
>         <td>âœ…</td>
>         <td colspan="2">âŒ</td>
>       </tr>
>       <tr>
>         <td>GPUè¦æ±‚</td>
>         <td>TuringåŠä»¥åæ¶æ„ï¼Œ6Gæ˜¾å­˜ä»¥ä¸Šæˆ–Apple Silicon</td>
>         <td colspan="2">TuringåŠä»¥åæ¶æ„ï¼Œ8Gæ˜¾å­˜ä»¥ä¸Š</td>
>       </tr>
>       <tr>
>         <td>å†…å­˜è¦æ±‚</td>
>         <td colspan="3">æœ€ä½16Gä»¥ä¸Šï¼Œæ¨è32Gä»¥ä¸Š</td>
>       </tr>
>       <tr>
>         <td>ç£ç›˜ç©ºé—´è¦æ±‚</td>
>         <td colspan="3">20Gä»¥ä¸Šï¼Œæ¨èä½¿ç”¨SSD</td>
>       </tr>
>       <tr>
>         <td>pythonç‰ˆæœ¬</td>
>         <td colspan="3">3.10-3.13</td>
>       </tr>
>     </tbody>
>   </table>
>
>   ```bash
>   Please select the model type to download: (pipeline, vlm, all) [all]:
>   ```
>
>   *å»ºè®®æ‚¨é€‰æ‹© `vlm` (MinerU2) ç‰ˆæœ¬ï¼Œå› ä¸ºå®ƒæä¾›äº†æ›´å¿«çš„è§£æé€Ÿåº¦ã€‚å¦‚æœæ‚¨å¯¹æ˜¾å­˜æœ‰ä¸¥æ ¼è¦æ±‚æˆ–åå¥½ä¼ ç»Ÿæµæ°´çº¿å¤„ç†ï¼Œå¯ä»¥é€‰æ‹© `pipeline` (MinerU1)ã€‚æ‚¨ä¹Ÿå¯ä»¥é€‰æ‹© `all` æ¥ä¸‹è½½æ‰€æœ‰å¯ç”¨ç‰ˆæœ¬ã€‚*
>
> #### 3. æ¨¡å‹è·¯å¾„é…ç½®
>
> `mineru.json` é…ç½®æ–‡ä»¶ä¼šåœ¨æ‚¨é¦–æ¬¡ä½¿ç”¨ `mineru-models-download` å‘½ä»¤æ—¶è‡ªåŠ¨ç”Ÿæˆã€‚æ¨¡å‹ä¸‹è½½å®Œæˆåï¼Œå…¶æœ¬åœ°è·¯å¾„å°†ä¼šåœ¨å½“å‰ç»ˆç«¯çª—å£æ˜¾ç¤ºï¼Œå¹¶è‡ªåŠ¨å†™å…¥æ‚¨ç”¨æˆ·ç›®å½•ä¸‹çš„ `mineru.json` æ–‡ä»¶ä¸­ï¼Œæ–¹ä¾¿åç»­ä½¿ç”¨ã€‚
>
> #### 4. MinerUç¯å¢ƒéªŒè¯
>
> æœ€ç®€å•çš„å‘½ä»¤è¡Œè°ƒç”¨æ–¹å¼æ¥è¿›è¡Œç¯å¢ƒéªŒè¯:
>
> ```bash
> mineru -p <input_path> -o <output_path> -b <MinerU_Backend> --source local
> ```
>
> * `<input_path>`ï¼šæœ¬åœ° PDF/å›¾ç‰‡æ–‡ä»¶æˆ–ç›®å½•ï¼ˆ`./demo.pdf`æˆ–`./image_dir`ï¼‰
> * `<output_path>`ï¼šè¾“å‡ºç›®å½•
> * `<mineru_backend>`ï¼šMinerU ç‰ˆæœ¬çš„é€‰æ‹©æ¥å£ï¼Œä½¿ç”¨`MinerU2`ï¼Œè¯·å°† `MinerU_Backend` å‚æ•°è®¾ç½®ä¸º `"vlm-sglang-engine"`ï¼›ä½¿ç”¨ `MinerU1`ï¼šè¯·å°† `MinerU_Backend` å‚æ•°è®¾ç½®ä¸º `"pipeline"`ã€‚
>
> #### 5. å·¥å…·ä½¿ç”¨
>
> `FileOrURLToMarkdownConverter` ç®—å­æä¾›äº† MinerU ç‰ˆæœ¬çš„é€‰æ‹©æ¥å£ï¼Œå…è®¸ç”¨æˆ·æ ¹æ®éœ€æ±‚é€‰æ‹©åˆé€‚çš„åç«¯å¼•æ“ã€‚
>
> * å¦‚æœç”¨æˆ·ä½¿ç”¨ `MinerU1`ï¼šè¯·å°† `MinerU_Backend` å‚æ•°è®¾ç½®ä¸º `"pipeline"`ã€‚è¿™å°†å¯ç”¨ä¼ ç»Ÿçš„æµæ°´çº¿å¤„ç†æ–¹å¼ã€‚
> * å¦‚æœç”¨æˆ·ä½¿ç”¨ `MinerU2` **(é»˜è®¤æ¨è)**ï¼šè¯·å°† `MinerU_Backend` å‚æ•°è®¾ç½®ä¸º `"vlm-sglang-engine"`ã€‚è¿™å°†å¯ç”¨åŸºäºå¤šæ¨¡æ€è¯­è¨€æ¨¡å‹çš„æ–°å¼•æ“ã€‚
>
> ```bash
> self.knowledge_cleaning_step1 = FileOrURLToMarkdownConverter(
>    intermediate_dir="../example_data/KBCleaningPipeline/raw/",
>    lang="en",
>    mineru_backend="vlm-sglang-engine",
>    raw_file = raw_file,
> )
> ```
>
> ğŸŒŸ**æ›´å¤šè¯¦æƒ…**ï¼šæœ‰å…³ MinerU çš„è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è€ƒå…¶ GitHub ä»“åº“ï¼š[MinerUå®˜æ–¹æ–‡æ¡£](https://github.com/opendatalab/MinerU)ã€‚

**è¾“å…¥**ï¼šåŸå§‹æ–‡æ¡£æ–‡ä»¶æˆ–URLï¼ˆä½¿ç”¨MinerU2ï¼‰ **è¾“å‡º**ï¼šæå–åçš„markdownæ–‡æœ¬

**ç¤ºä¾‹**ï¼š

```python
file_to_markdown_converter = FileOrURLToMarkdownConverter(
    intermediate_dir="../example_data/KBCleaningPipeline/raw/",
    lang="en",
    mineru_backend="vlm-sglang-engine",
    raw_file = raw_file,
)
extracted=file_to_markdown_converter.run(
    storage=self.storage,
)
```

### 2. æ–‡æœ¬åˆ†å—

æ–‡æ¡£è¢«æå–ä¹‹åï¼Œæ–‡æœ¬åˆ†å—(KBCChunkGenerator)æ­¥éª¤å°†æå–ä¸­çš„é•¿æ–‡æœ¬åˆ‡åˆ†æˆå—ï¼Œç³»ç»Ÿæ”¯æŒé€šè¿‡token, character, sentence, semanticç»´åº¦è¿›è¡Œåˆ†å—ã€‚

**è¾“å…¥**ï¼šæå–åçš„Markdownæ–‡æœ¬ **è¾“å‡º**ï¼šåˆ†å—åçš„jsonæ–‡ä»¶

**ç¤ºä¾‹**ï¼š

```python
text_splitter = KBCChunkGenerator(
    split_method="token",
    chunk_size=512,
    tokenizer_name="Qwen/Qwen2.5-7B-Instruct",
)
text_splitter.run(
    storage=self.storage.step(),
    input_file=extracted,
    output_key="raw_content",
)
```

### 3. çŸ¥è¯†æ¸…æ´—

æ–‡æœ¬è¢«åˆ‡å—ä¹‹åï¼ŒçŸ¥è¯†æ¸…æ´—(KBCTextCleaner)ä¸“é—¨ç”¨äºå¯¹RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ç³»ç»Ÿä¸­çš„åŸå§‹çŸ¥è¯†å†…å®¹è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ã€‚è¯¥è¿‡ç¨‹é€šè¿‡å¤§è¯­è¨€æ¨¡å‹æ¥å£ï¼Œå®ç°å¯¹éç»“æ„åŒ–çŸ¥è¯†çš„æ™ºèƒ½æ¸…æ´—å’Œæ ¼å¼åŒ–ï¼Œæå‡çŸ¥è¯†åº“çš„å‡†ç¡®æ€§å’Œå¯è¯»æ€§ã€‚

**è¾“å…¥**ï¼šåˆ†å—åçš„jsonæ–‡ä»¶ **è¾“å‡º**ï¼šæ¸…æ´—åçš„jsonæ–‡ä»¶

```python
knowledge_cleaner = KBCTextCleaner(
    llm_serving=api_llm_serving,
    lang="en"
)
extracted_path = knowledge_cleaner.run(
  storage=self.storage.step(),
  input_key= "raw_content",
  output_key="cleaned",
)
```

### 4. QAç”Ÿæˆ

çŸ¥è¯†è¢«æ¸…æ´—ä¹‹åï¼Œå¤šè·³QAåˆæˆ(KBCMultiHopQAGenerator)ä¸“é—¨ç”¨äºä»æ–‡æœ¬æ•°æ®ä¸­è‡ªåŠ¨ç”Ÿæˆéœ€è¦å¤šæ­¥æ¨ç†çš„é—®é¢˜-ç­”æ¡ˆå¯¹ã€‚è¯¥è¿‡ç¨‹é€šè¿‡å¤§è¯­è¨€æ¨¡å‹æ¥å£ï¼Œå®ç°å¯¹æ–‡æœ¬çš„æ™ºèƒ½åˆ†æå’Œå¤æ‚é—®é¢˜æ„å»ºï¼Œé€‚ç”¨äºæ„å»ºé«˜è´¨é‡çš„å¤šè·³é—®ç­”æ•°æ®é›†ã€‚æ ¹æ®[MIRIAD](https://github.com/eth-medical-ai-lab/MIRIAD)çš„å®éªŒï¼Œè¿™ç§QAæ ¼å¼çš„çŸ¥è¯†æ›´æœ‰åˆ©äºRAGå‡†ç¡®æ¨ç†ã€‚

**è¾“å…¥**ï¼šjsonæ ¼å¼çš„æ™®é€šæ–‡æœ¬

**è¾“å‡º**ï¼šé’ˆå¯¹æ¯ä¸€æ¡æ–‡æœ¬åˆæˆä¸€ç»„å¤šè·³é—®ç­” è¾“å‡ºjsonæ ¼å¼

**ä½¿ç”¨ç¤ºä¾‹**ï¼š

```python
multi_hop_qa_generator = KBCMultiHopQAGenerator(
    llm_serving=local_llm_serving,
    lang="en"
)
multi_hop_qa_generator.run(
    storage=self.storage.step(),
    input_key="cleaned",
    output_key="MultiHop_QA"
)
```

### 5. åŸºäºDataflow[vllm]å¤„ç†æ•™ç¨‹

> *ç”±äº `MinerU` åŸºäºæœ€æ–°ç‰ˆæœ¬ `SGLang` éƒ¨ç½²ï¼Œæ•… `Dataflow[vllm]` åº”å½“ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬ `vllm` è¿›è¡Œå®‰è£…ã€‚*

```bash
conda create -n dataflow python=3.10
conda activate dataflow
git clone https://github.com/OpenDCAI/DataFlow.git
cd DataFlow
pip install -e .
pip install -U "mineru[all]"
pip install vllm==0.9.2
pip install "numpy>=1.24,<2.0.0"
```

## 3. è¿è¡Œç¤ºä¾‹

ç”¨æˆ·æ‰§è¡Œä¸‹é¢çš„è„šæœ¬å¯ä»¥æ»¡è¶³ä¸ç”¨çš„æ•°æ®éœ€æ±‚ï¼Œæ³¨æ„gpu_pipelines, api_pipelines, cpu_pipelinesä¸‹é¢çš„è„šæœ¬åˆ†åˆ«é€‚ç”¨äºæµ‹è¯•æœºé…æœ‰GPUï¼Œç”¨æˆ·é…ç½®äº†APIä»¥åŠå…¶ä»–æƒ…å†µã€‚

> *å…¶ä¸­åŸºäº `Dataflow[vllm]` å¯ä»¥è¿è¡Œ `gpu_pipelines/*_vllm.py` è„šæœ¬ï¼ŒåŸºäº `Dataflow[sglang]` å¯ä»¥è¿è¡Œ `gpu_pipelines/*_sglang.py` è„šæœ¬*

- PDFæ–‡ä»¶çŸ¥è¯†åº“æ¸…æ´—æ„å»º

  ```shell
  python gpu_pipelines/kbcleaning/kbcleaning_pipeline_pdf_vllm.py 
  python gpu_pipelines/kbcleaningkbcleaning_pipeline_pdf_sglang.py 
  ```
    [kbcleaning_pipeline_pdf_vllm.py](https://github.com/OpenDCAI/DataFlow/blob/main/dataflow/statics/pipelines/gpu_pipelines/kbcleaning/kbcleaning_pipeline_pdf_vllm.py) 
    [kbcleaning_pipeline_pdf_sglang.py ](https://github.com/OpenDCAI/DataFlow/blob/main/dataflow/statics/pipelines/gpu_pipelines/kbcleaning/kbcleaning_pipeline_pdf_sglang.py)

- URLçˆ¬å–åçŸ¥è¯†åº“æ¸…æ´—æ„å»º

  ```shell
  python gpu_pipelines/kbcleaning/kbcleaning_pipeline_url_vllm.py 
  python gpu_pipelines/kbcleaning/kbcleaning_pipeline_url_sglang.py 
  ```
    [kbcleaning_pipeline_url_vllm.py](https://github.com/OpenDCAI/DataFlow/blob/main/dataflow/statics/pipelines/gpu_pipelines/kbcleaning/kbcleaning_pipeline_url_vllm.py)
    [kbcleaning_pipeline_url_sglang.py](https://github.com/OpenDCAI/DataFlow/blob/main/dataflow/statics/pipelines/gpu_pipelines/kbcleaning/kbcleaning_pipeline_url_sglang.py)

## 4. æµæ°´çº¿ç¤ºä¾‹

ä»¥ä¸‹ç»™å‡ºåŸºäº`Dataflow[vllm]`ç¯å¢ƒé…ç½®çš„ç¤ºä¾‹æµæ°´çº¿ï¼Œæ¼”ç¤ºå¦‚ä½•ä½¿ç”¨å¤šä¸ªç®—å­è¿›è¡ŒçŸ¥è¯†åº“æ¸…æ´—ã€‚è¯¥ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•åˆå§‹åŒ–ä¸€ä¸ªçŸ¥è¯†åº“æ¸…æ´—æµæ°´çº¿ï¼Œå¹¶ä¸”é¡ºåºæ‰§è¡Œå„ä¸ªæå–å’Œæ¸…ç†æ­¥éª¤ã€‚

```python
from dataflow.operators.knowledge_cleaning import (
    KBCChunkGenerator,
    FileOrURLToMarkdownConverter,
    KBCTextCleaner,
    KBCMultiHopQAGenerator,
)
from dataflow.utils.storage import FileStorage
from dataflow.serving import APILLMServing_request

class KBCleaningPDF_APIPipeline():
    def __init__(self, url:str=None, raw_file:str=None):

        self.storage = FileStorage(
            first_entry_file_name="../example_data/KBCleaningPipeline/kbc_placeholder.json",
            cache_path="./.cache/api",
            file_name_prefix="pdf_cleaning_step",
            cache_type="json",
        )

        self.llm_serving = APILLMServing_request(
                api_url="https://api.openai.com/v1/chat/completions",
                model_name="gpt-4o",
                max_workers=100
        )

        self.knowledge_cleaning_step1 = FileOrURLToMarkdownConverter(
            intermediate_dir="../example_data/KBCleaningPipeline/raw/",
            lang="en",
            mineru_backend="vlm-sglang-engine",
            raw_file = raw_file,
        )

        self.knowledge_cleaning_step2 = KBCChunkGenerator(
            split_method="token",
            chunk_size=512,
            tokenizer_name="Qwen/Qwen2.5-7B-Instruct",
        )

        self.knowledge_cleaning_step3 = KBCTextCleaner(
            llm_serving=self.llm_serving,
            lang="en"
        )

        self.knowledge_cleaning_step4 = KBCMultiHopQAGenerator(
            llm_serving=self.llm_serving,
            lang="en"
        )

    def forward(self):
        extracted=self.knowledge_cleaning_step1.run(
            storage=self.storage,
        )
        
        self.knowledge_cleaning_step2.run(
            storage=self.storage.step(),
            input_file=extracted,
            output_key="raw_content",
        )

        self.knowledge_cleaning_step3.run(
            storage=self.storage.step(),
            input_key= "raw_content",
            output_key="cleaned",
        )
        self.knowledge_cleaning_step4.run(
            storage=self.storage.step(),
            input_key="cleaned",
            output_key="MultiHop_QA"
        )
        
if __name__ == "__main__":
    model = KBCleaningPDF_APIPipeline(raw_file="../example_data/KBCleaningPipeline/test.pdf")
    model.forward()
```
