import{_ as i,c as r,b as d,a as e,d as s,e as n,w as l,r as o,o as p}from"./app-BqDkFDvD.js";const c={};function g(h,t){const a=o("VPLink");return p(),r("div",null,[t[5]||(t[5]=d(`<h2 id="overview" tabindex="-1"><a class="header-anchor" href="#overview"><span>Overview</span></a></h2><p>DataFlow currently supports text data processing at the data point level, categorized into three types: refiners, deduplicators and filters.</p><table class="tg"><thead><tr><th class="tg-0pky">Type</th><th class="tg-0pky">Count</th><th class="tg-0pky">Description</th></tr></thead><tbody><tr><td class="tg-0pky">Refiners</td><td class="tg-0pky">16</td><td class="tg-0pky">Improves the content of data points through processing and augmentation without altering the total count.</td></tr><tr><td class="tg-0pky">Deduplicators</td><td class="tg-0pky">6</td><td class="tg-0pky">Removes duplicate data points using methods such as hashing.</td></tr><tr><td class="tg-0pky">Filters</td><td class="tg-0pky">42</td><td class="tg-0pky">Filters data points based on thresholds and other criteria.</td></tr></tbody></table><h2 id="refiners" tabindex="-1"><a class="header-anchor" href="#refiners"><span>Refiners</span></a></h2><table class="tg"><thead><tr><th class="tg-0pky">Name</th><th class="tg-0pky">Applicable Type</th><th class="tg-0pky">Description</th><th class="tg-0pky">Repository or Paper</th></tr></thead><tbody><tr><td class="tg-0pky">CondorRefiner</td><td class="tg-0pky">SFT</td><td class="tg-0pky">Generate evaluations and rewrites of SFT responses using LLM APIs to improve QA quality</td><td class="tg-0pky"><a href="https://arxiv.org/pdf/2501.12273">paper</a></td></tr><tr><td class="tg-0pky">LowercaseRefiner</td><td class="tg-0pky">NLP</td><td class="tg-0pky">Converts text fields to lowercase.</td><td class="tg-0pky">-</td></tr><tr><td class="tg-0pky">PIIAnonymizeRefiner</td><td class="tg-0pky">Pre-training</td><td class="tg-0pky">Anonymizes Personally Identifiable Information (PII), such as names and locations, to protect privacy.</td><td class="tg-0pky"><a href="https://github.com/microsoft/presidio">Code</a></td></tr><tr><td class="tg-0pky">RemovePunctuationRefiner</td><td class="tg-0pky">NLP</td><td class="tg-0pky">Removes punctuation from text.</td><td class="tg-0pky">-</td></tr><tr><td class="tg-0pky">RemoveNumberRefiner</td><td class="tg-0pky">NLP</td><td class="tg-0pky">Removes numeric characters from text.</td><td class="tg-0pky">-</td></tr><tr><td class="tg-0pky">RemoveExtraSpacesRefiner</td><td class="tg-0pky">NLP, Pre-training</td><td class="tg-0pky">Replaces multiple consecutive spaces with a single space and trims leading/trailing spaces.</td><td class="tg-0pky">-</td></tr><tr><td class="tg-0pky">RemoveRepetitionsPunctuationRefiner</td><td class="tg-0pky">NLP</td><td class="tg-0pky">Removes repeated punctuation, e.g., &quot;!!!&quot; becomes &quot;!&quot;.</td><td class="tg-0pky">-</td></tr><tr><td class="tg-0pky">RemoveEmojiRefiner</td><td class="tg-0pky">Pre-training</td><td class="tg-0pky">Removes emojis from text, e.g., &quot;ðŸ˜€&quot;.</td><td class="tg-0pky"><a href="https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b">Code</a></td></tr><tr><td class="tg-0pky">RemoveEmoticonsRefiner</td><td class="tg-0pky">Pre-training</td><td class="tg-0pky">Removes emoticons such as &quot;:-)&quot;, using a predefined list.</td><td class="tg-0pky"><a href="https://github.com/NeelShah18/emot/blob/master/emot/emo_unicode.py">Code</a></td></tr><tr><td class="tg-0pky">RemoveContractionsRefiner</td><td class="tg-0pky">NLP</td><td class="tg-0pky">Expands contractions in text, e.g., &quot;can&#39;t&quot; becomes &quot;cannot&quot;.</td><td class="tg-0pky"><a href="https://github.com/kootenpv/contractions">Code</a></td></tr><tr><td class="tg-0pky">HtmlUrlRemoverRefiner</td><td class="tg-0pky">Pre-training</td><td class="tg-0pky">Removes URLs and HTML tags from text.</td><td class="tg-0pky">-</td></tr><tr><td class="tg-0pky">TextNormalizationRefiner</td><td class="tg-0pky">NLP</td><td class="tg-0pky">Normalizes formats for dates, currencies, etc., in text.</td><td class="tg-0pky">-</td></tr><tr><td class="tg-0pky">NERRefiner</td><td class="tg-0pky">NLP</td><td class="tg-0pky">Uses Named Entity Recognition (NER) to identify and mask specific entities in text.</td><td class="tg-0pky"><a href="https://spacy.io/usage/linguistic-features#named-entities">Code</a></td></tr><tr><td class="tg-0pky">StemmingLemmatizationRefiner</td><td class="tg-0pky">NLP</td><td class="tg-0pky">Performs stemming or lemmatization on text.</td><td class="tg-0pky"><a href="https://www.nltk.org/">Code</a></td></tr><tr><td class="tg-0pky">SpellingCorrectionRefiner</td><td class="tg-0pky">NLP, Pre-training</td><td class="tg-0pky">Corrects spelling errors in text using SymSpell.</td><td class="tg-0pky"><a href="https://github.com/mammothb/symspellpy">Code</a></td></tr><tr><td class="tg-0pky">RemoveStopwordsRefiner</td><td class="tg-0pky">NLP</td><td class="tg-0pky">Removes stopwords (e.g., &quot;the&quot;, &quot;is&quot;) from text.</td><td class="tg-0pky"><a href="https://github.com/nltk/nltk">Code</a></td></tr></tbody></table><h2 id="deduplicators" tabindex="-1"><a class="header-anchor" href="#deduplicators"><span>Deduplicators</span></a></h2><table class="tg"><thead><tr><th class="tg-0pky">Name</th><th class="tg-0pky">Type</th><th class="tg-0pky">Description</th><th class="tg-0pky">Repository or Paper</th></tr></thead><tbody><tr><td class="tg-0pky">HashDeduplicator</td><td class="tg-0pky">Exact Deduplication</td><td class="tg-0pky">Uses various hash functions (e.g., MD5, SHA256, XXH3_128) to remove duplicate data based on exact hash value comparison. Suitable for small-scale simple deduplication.</td><td class="tg-0pky">-</td></tr><tr><td class="tg-0pky">CCNetDeduplicator</td><td class="tg-0pky">Exact Deduplication</td><td class="tg-0pky">Compares the first 64 bits of the SHA-1 hash to identify duplicate text, balancing security and computational efficiency.</td><td class="tg-0pky">-</td></tr><tr><td class="tg-0pky">NgramHashDeduplicator</td><td class="tg-0pky">Near Deduplication</td><td class="tg-0pky">Combines n-gram techniques with hashing to detect duplicates based on multiple hash comparisons of n-gram segments. Useful for identifying near-duplicates.</td><td class="tg-0pky"><a href="https://arxiv.org/abs/1607.04606">Paper</a></td></tr><tr><td class="tg-0pky">SemDeduplicator</td><td class="tg-0pky">Near Deduplication</td><td class="tg-0pky">Uses semantic similarity based on BERT embeddings and cosine similarity to detect duplicates. Ideal for detecting semantically similar but differently phrased text.</td><td class="tg-0pky"><a href="https://arxiv.org/abs/1810.04805">Paper</a> <br> <a href="https://github.com/facebookresearch/SemDeDup">Code</a></td></tr><tr><td class="tg-0pky">SimHashDeduplicator</td><td class="tg-0pky">Near Deduplication</td><td class="tg-0pky">Uses the SimHash algorithm to detect similar text based on Hamming distance of fingerprints. Efficient for large-scale data deduplication.</td><td class="tg-0pky"><a href="https://dl.acm.org/doi/abs/10.1145/1242572.1242592">Paper</a></td></tr><tr><td class="tg-0pky">MinHashDeduplicator</td><td class="tg-0pky">Near Deduplication</td><td class="tg-0pky">Combines MinHash and LSH to compare sets with minimal memory usage and computation cost, detecting similarity between sets.</td><td class="tg-0pky"><a href="https://arxiv.org/abs/1811.04633">Paper</a></td></tr></tbody></table><h2 id="filters" tabindex="-1"><a class="header-anchor" href="#filters"><span>Filters</span></a></h2><table class="tg"><thead><tr><th class="tg-0pky">Name</th><th class="tg-0pky">Applicable Type</th><th class="tg-0pky">Description</th><th class="tg-0pky">Repository or Paper</th></tr></thead><tbody><tr><td class="tg-0pky">GeneralFilter</td><td class="tg-0pky">Any DataFrame</td><td class="tg-0pky">Supports flexible filtering of the DataFrame using one or more custom lambda functions</td><td class="tg-0pky"> - </td></tr><tr><td class="tg-0pky">LanguageFilter</td><td class="tg-0pky">Pre-training, SFT</td><td class="tg-0pky">Filters specific languages using the fasttext language identification model.</td><td class="tg-0pky"><a href="https://huggingface.co/facebook/fasttext-language-identification">Huggingface</a></td></tr><tr><td class="tg-0pky">BlocklistFilter</td><td class="tg-0pky">Pre-training, SFT</td><td class="tg-0pky">Filters data points using a blocklist (e.g., List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words).</td><td class="tg-0pky"><a href="https://github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words?tab=readme-ov-file">Code</a></td></tr></tbody></table><p>Additionally, Open-DataFlow-Eval supports filtering data points based on scores from single data point scorers, with 18 supported scorers.</p><div class="language-yaml line-numbers-mode" data-highlighter="shiki" data-ext="yaml" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-yaml"><span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">DeitaQualityFilter</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span></span>
<span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">    min_score</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 1</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">                                         </span></span>
<span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">    max_score</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 5</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">                                      </span></span>
<span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">    scorer_args</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span></span>
<span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">      device</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &#39;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">cuda:0</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&#39;</span></span>
<span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">      model_name</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &#39;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">hkust-nlp/deita-quality-scorer</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&#39;</span></span>
<span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">      max_length</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 512</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,11)),e("p",null,[t[1]||(t[1]=s("You can set min/max scores and scorer parameters in ")),t[2]||(t[2]=e("code",null,"scorer_args",-1)),t[3]||(t[3]=s(" for filtering. For more information on supported scorers, refer to the ")),n(a,{href:"/en/guide/text_evaluation_operators/"},{default:l(()=>t[0]||(t[0]=[s("evaluation algorithm documentation")])),_:1,__:[0]}),t[4]||(t[4]=s(" (excluding the Diversity part)."))]),t[6]||(t[6]=e("p",null,[s("In addition, heuristic rule filtering plays a significant role in the screening of pre-training data. In this regard, the "),e("a",{href:"https://github.com/DataEval/dingo",target:"_blank",rel:"noopener noreferrer"},"Dingo Data Quality Evaluation Tool"),s(" has greatly inspired our development. We have integrated some of the rule filtering algorithms used in Dingo, a total of 22 types, into "),e("code",null,"dataflow/operators/filter/GeneralText/heuristics.py"),s(". For details, please refer to the "),e("a",{href:"https://github.com/DataEval/dingo/blob/dev/docs/rules.md",target:"_blank",rel:"noopener noreferrer"},"Rules Documentation"),s(". The names of the filters can be found in the "),e("code",null,"dataflow/operators/filter/GeneralText/heuristics.py"),s(" file.")],-1)),t[7]||(t[7]=e("p",null,[s("All 42 data filters mentioned above share the same "),e("code",null,"yaml"),s(" invocation method.")],-1))])}const y=i(c,[["render",g]]),m=JSON.parse('{"path":"/en/guide/text_process_operators/","title":"General Data Processing Operators","lang":"en-US","frontmatter":{"title":"General Data Processing Operators","createTime":"2025/06/09 11:43:25","permalink":"/en/guide/text_process_operators/"},"readingTime":{"minutes":4.83,"words":1449},"git":{"createdTime":1749441278000,"updatedTime":1753157108000,"contributors":[{"name":"Sunnyhaze","username":"Sunnyhaze","email":"mxch1122@126.com","commits":1,"avatar":"https://avatars.githubusercontent.com/Sunnyhaze?v=4","url":"https://github.com/Sunnyhaze"},{"name":"Ma, Xiaochen","username":"","email":"mxch1122@126.com","commits":2,"avatar":"https://gravatar.com/avatar/c86bc98abf428aa442dfc12c76e70e324a551ebc637e5ed6634d60fbd3811221?d=retro"},{"name":"zzy1127","username":"zzy1127","email":"1726073424@qq.com","commits":10,"avatar":"https://avatars.githubusercontent.com/zzy1127?v=4","url":"https://github.com/zzy1127"},{"name":"Hao Liang","username":"","email":"hao.liang@stu.pku.edu.cn","commits":1,"avatar":"https://gravatar.com/avatar/105bae3e8661728b9f2f5440992b04f5f28459b66a049d09b52213ce1438f6bc?d=retro"},{"name":"wongzhenhao","username":"wongzhenhao","email":"zhenhao1141@gmail.com","commits":1,"avatar":"https://avatars.githubusercontent.com/wongzhenhao?v=4","url":"https://github.com/wongzhenhao"}]},"filePathRelative":"en/notes/guide/general_operators/text_process_operators.md","headers":[]}');export{y as comp,m as data};
