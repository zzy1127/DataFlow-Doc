import{_ as e,c as d,b as r,o as a}from"./app-BqDkFDvD.js";const s={};function h(o,t){return a(),d("div",null,t[0]||(t[0]=[r('<h2 id="纯视频评估指标" tabindex="-1"><a class="header-anchor" href="#纯视频评估指标"><span>纯视频评估指标</span></a></h2><h3 id="指标分类" tabindex="-1"><a class="header-anchor" href="#指标分类"><span>指标分类</span></a></h3><table><thead><tr><th>类别描述</th><th>指标列表</th></tr></thead><tbody><tr><td>基于视频统计信息</td><td>Motion Score</td></tr><tr><td>基于预训练模型</td><td>FastVQAScorer, FasterVQAScorer, DOVERScorer</td></tr></tbody></table><h3 id="指标介绍" tabindex="-1"><a class="header-anchor" href="#指标介绍"><span>指标介绍</span></a></h3><table><thead><tr><th>名称</th><th>评估指标</th><th>评估维度</th><th>简介</th><th>取值范围</th></tr></thead><tbody><tr><td>VideoMotionScorer</td><td>Motion Score</td><td>统计</td><td>计算帧之间的光流向量的幅度作为评分</td><td></td></tr><tr><td><a href="https://arxiv.org/abs/2207.02595v1" target="_blank" rel="noopener noreferrer">FastVQAScorer</a></td><td>预训练模型打分</td><td>模型</td><td>基于Video Swin Transformer的打分器，加入了Fragment Sampling模块，获得了准确性和速度的提升</td><td>[0,1]</td></tr><tr><td><a href="https://arxiv.org/abs/2210.05357" target="_blank" rel="noopener noreferrer">FasterVQAScorer</a></td><td>预训练模型打分</td><td>模型</td><td>基于Video Swin Transformer的打分器，在FastVQAScorer的基础上对Fragment Sampling模块进行优化，得到了显著的速度提升</td><td>[0,1]</td></tr><tr><td><a href="https://arxiv.org/abs/2211.04894" target="_blank" rel="noopener noreferrer">DOVERScorer</a></td><td>预训练模型打分</td><td>模型</td><td>基于FastVQAScorer的打分器，同时给出了从技术和美学两个角度的评分</td><td></td></tr></tbody></table><h3 id="参考值" tabindex="-1"><a class="header-anchor" href="#参考值"><span>参考值</span></a></h3><p>为更好的提供数据质量参考，我们使用以上指标对KoNViD-1k数据集进行评估，得到的指标数值分布如下:</p><table class="tg"><thead><tr><th class="tg-0pky">指标</th><th class="tg-0pky">名称</th><th class="tg-0pky">简介</th><th class="tg-0pky">均值</th><th class="tg-0pky">方差</th><th class="tg-0pky">最大值</th><th class="tg-0pky">最小值</th></tr></thead><tbody><tr><td class="tg-0pky">Motion Score</td><td class="tg-0pky"></td><td class="tg-0pky">计算视频帧之间的光流向量的幅度作为评分，视频中的运动越强烈，帧之间的变化越大，分数越高</td><td class="tg-0pky">6.2745</td><td class="tg-0pky">19.28</td><td class="tg-0pky">25.23</td><td class="tg-0pky">0.001623</td></tr><tr><td class="tg-0pky">FastVQA</td><td class="tg-0pky"></td><td class="tg-0pky">使用FastVQAScorer模块得到的评分，视频质量越好，分数越高</td><td class="tg-0pky">0.4987</td><td class="tg-0pky">0.04554</td><td class="tg-0pky">0.9258</td><td class="tg-0pky">0.007619</td></tr><tr><td class="tg-0pky">FasterVQA</td><td class="tg-0pky"></td><td class="tg-0pky">使用FasterVQAScorer模块得到的评分，视频质量越好，分数越高</td><td class="tg-0pky">0.5134</td><td class="tg-0pky">0.04558</td><td class="tg-0pky">0.9066</td><td class="tg-0pky">0.03686</td></tr><tr><td class="tg-0pky" rowspan="2">DOVER</td><td class="tg-0pky">technical</td><td class="tg-0pky">使用DOVERScorer模块得到的评分之一，视频在技术方面的质量越好，分数越高</td><td class="tg-0pky">-0.1107</td><td class="tg-0pky">0.001755</td><td class="tg-0pky">-0.006550</td><td class="tg-0pky">-0.3175</td></tr><tr><td class="tg-0pky">aesthetic</td><td class="tg-0pky">使用DOVERScorer模块得到的评分之一，视频在美学方面的质量越好，分数越高</td><td class="tg-0pky">-0.008419</td><td class="tg-0pky">0.004569</td><td class="tg-0pky">0.1869</td><td class="tg-0pky">-0.2629</td></tr></tbody></table><h2 id="视频-文本评估指标" tabindex="-1"><a class="header-anchor" href="#视频-文本评估指标"><span>视频-文本评估指标</span></a></h2><table><thead><tr><th>类别描述</th><th>指标列表</th></tr></thead><tbody><tr><td>基于预训练图文模型</td><td>EMScore, PAC-S</td></tr></tbody></table><table><thead><tr><th>名称</th><th>评估指标</th><th>评估维度</th><th>简介</th><th>取值范围</th></tr></thead><tbody><tr><td><a href="https://arxiv.org/abs/2111.08919" target="_blank" rel="noopener noreferrer">EMScorer</a></td><td>基于视频-文本相似度的打分</td><td>模型</td><td>基于CLIP的视频-文本打分器，同时支持with-reference和no-reference的打分功能</td><td>[0,1]</td></tr><tr><td><a href="https://arxiv.org/abs/2303.12112" target="_blank" rel="noopener noreferrer">PACScorer</a></td><td>基于视频-文本相似度的打分</td><td>模型</td><td>基于CLIP的视频-文本打分器，在EMScore的基础上对CLIP Encoder进行了调优</td><td>[0,1]</td></tr></tbody></table><h3 id="参考值-1" tabindex="-1"><a class="header-anchor" href="#参考值-1"><span>参考值</span></a></h3><p>为更好的提供数据质量参考，我们使用以上指标对VATEX数据集(<a href="https://huggingface.co/datasets/lmms-lab/VATEX" target="_blank" rel="noopener noreferrer">链接</a>)进行评估，得到的指标数值分布如下:</p><table><thead><tr><th>Metric</th><th>Name</th><th>Description</th><th>Mean</th><th>Variance</th><th>Max</th><th>Min</th></tr></thead><tbody><tr><td>EMScorer</td><td>figr_F</td><td>The score obtained using the EMScorer module. The higher the similarity between the video and text at a fine-grained level, the higher the score</td><td>0.2712</td><td>0.0003667</td><td>0.3461</td><td>0.1987</td></tr><tr><td></td><td>cogr</td><td>The score obtained using the EMScorer module. The higher the similarity between the video and text at a coarse-grained level, the higher the score</td><td>0.3106</td><td>0.0009184</td><td>0.4144</td><td>0.18</td></tr><tr><td></td><td>full_F</td><td>The score obtained using the EMScorer module, which is the arithmetic mean of the above two scores</td><td>0.2909</td><td>0.0005776</td><td>0.3712</td><td>0.3807</td></tr><tr><td>PACScorer</td><td>figr_F</td><td>The score obtained using the PACScorer module. The higher the similarity between the video and text at a fine-grained level, the higher the score</td><td>0.36553</td><td>0.0004902</td><td>0.4456</td><td>0.2778</td></tr><tr><td></td><td>cogr</td><td>The score obtained using the PACScorer module. The higher the similarity between the video and text at a coarse-grained level, the higher the score</td><td>0.4160</td><td>0.001021</td><td>0.5222</td><td>0.2510</td></tr><tr><td></td><td>full_F</td><td>The score obtained using the PACScorer module, which is the arithmetic mean of the above two scores</td><td>0.3908</td><td>0.0006854</td><td>0.4761</td><td>0.2681</td></tr></tbody></table>',14)]))}const n=e(s,[["render",h]]),i=JSON.parse('{"path":"/zh/guide/92inyi3j/","title":"视频数据评估指标","lang":"zh-CN","frontmatter":{"title":"视频数据评估指标","createTime":"2025/06/09 11:43:42","permalink":"/zh/guide/92inyi3j/"},"readingTime":{"minutes":3.86,"words":1157},"git":{"createdTime":1749441278000,"updatedTime":1750128958000,"contributors":[{"name":"Sunnyhaze","username":"Sunnyhaze","email":"mxch1122@126.com","commits":3,"avatar":"https://avatars.githubusercontent.com/Sunnyhaze?v=4","url":"https://github.com/Sunnyhaze"},{"name":"Ma, Xiaochen","username":"","email":"mxch1122@126.com","commits":1,"avatar":"https://gravatar.com/avatar/c86bc98abf428aa442dfc12c76e70e324a551ebc637e5ed6634d60fbd3811221?d=retro"}]},"filePathRelative":"zh/notes/guide/metrics/video_metrics.md","headers":[]}');export{n as comp,i as data};
