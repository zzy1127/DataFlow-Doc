import{_ as e,c as s,b as i,o as a}from"./app-BqDkFDvD.js";const n={};function l(r,t){return a(),s("div",null,t[0]||(t[0]=[i('<h2 id="ðŸ“˜-overview" tabindex="-1"><a class="header-anchor" href="#ðŸ“˜-overview"><span>ðŸ“˜ Overview</span></a></h2><p>The <code>RAREReasonDistillGenerator</code> is an operator designed to distill reasoning capabilities from Large Language Models (LLMs). It functions by generating a detailed, step-by-step thought process. The operator takes a question, a scenario, a relevant positive document, and several hard negative documents as input to construct a prompt, which is then used to guide the LLM in generating the reasoning chain.</p><h2 id="init" tabindex="-1"><a class="header-anchor" href="#init"><span><code>__init__</code></span></a></h2><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">def</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;"> __init__</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">self</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> llm_serving</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> LLMServingABC</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="init-parameters" tabindex="-1"><a class="header-anchor" href="#init-parameters"><span><code>__init__</code> Parameters</span></a></h3><table><thead><tr><th style="text-align:left;">Parameter</th><th style="text-align:left;">Type</th><th style="text-align:left;">Default</th><th style="text-align:left;">Description</th></tr></thead><tbody><tr><td style="text-align:left;"><strong>llm_serving</strong></td><td style="text-align:left;">LLMServingABC</td><td style="text-align:left;">Required</td><td style="text-align:left;">Large Language Model serving instance, used to execute inference and generation.</td></tr></tbody></table><h3 id="prompt-template-descriptions" tabindex="-1"><a class="header-anchor" href="#prompt-template-descriptions"><span>Prompt Template Descriptions</span></a></h3><table><thead><tr><th style="text-align:left;">Prompt Template Name</th><th style="text-align:left;">Primary Use</th><th style="text-align:left;">Applicable Scenarios</th><th style="text-align:left;">Feature Description</th></tr></thead><tbody><tr><td style="text-align:left;"></td><td style="text-align:left;"></td><td style="text-align:left;"></td><td style="text-align:left;"></td></tr></tbody></table><h2 id="run" tabindex="-1"><a class="header-anchor" href="#run"><span><code>run</code></span></a></h2><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">def</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;"> run</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">storage</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> input_text_key</span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">=</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">text</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> input_question_key</span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">=</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">question</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> input_scenario_key</span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">=</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">scenario</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> input_hardneg_key</span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">=</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">hard_negatives</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> output_key</span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">=</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">reasoning</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>Executes the operator&#39;s main logic. It reads an input DataFrame from storage, constructs prompts by combining the question, scenario, and documents, generates reasoning from the LLM, and writes the result back to storage.</p><h4 id="parameters" tabindex="-1"><a class="header-anchor" href="#parameters"><span>Parameters</span></a></h4><table><thead><tr><th style="text-align:left;">Name</th><th style="text-align:left;">Type</th><th style="text-align:left;">Default</th><th style="text-align:left;">Description</th></tr></thead><tbody><tr><td style="text-align:left;"><strong>storage</strong></td><td style="text-align:left;">DataFlowStorage</td><td style="text-align:left;">Required</td><td style="text-align:left;">Data flow storage instance, responsible for reading and writing data.</td></tr><tr><td style="text-align:left;"><strong>input_text_key</strong></td><td style="text-align:left;">str</td><td style="text-align:left;">&quot;text&quot;</td><td style="text-align:left;">Field name for the positive document.</td></tr><tr><td style="text-align:left;"><strong>input_question_key</strong></td><td style="text-align:left;">str</td><td style="text-align:left;">&quot;question&quot;</td><td style="text-align:left;">Field name for the question.</td></tr><tr><td style="text-align:left;"><strong>input_scenario_key</strong></td><td style="text-align:left;">str</td><td style="text-align:left;">&quot;scenario&quot;</td><td style="text-align:left;">Field name for the scenario.</td></tr><tr><td style="text-align:left;"><strong>input_hardneg_key</strong></td><td style="text-align:left;">str</td><td style="text-align:left;">&quot;hard_negatives&quot;</td><td style="text-align:left;">Field name for the list of hard negatives.</td></tr><tr><td style="text-align:left;"><strong>output_key</strong></td><td style="text-align:left;">str</td><td style="text-align:left;">&quot;reasoning&quot;</td><td style="text-align:left;">Field name for storing the generated reasoning.</td></tr></tbody></table><h2 id="ðŸ§ -example-usage" tabindex="-1"><a class="header-anchor" href="#ðŸ§ -example-usage"><span>ðŸ§  Example Usage</span></a></h2><h4 id="ðŸ§¾-default-output-format" tabindex="-1"><a class="header-anchor" href="#ðŸ§¾-default-output-format"><span>ðŸ§¾ Default Output Format</span></a></h4><p>The operator adds a new column (specified by <code>output_key</code>) to the input dataframe. This new column contains the reasoning string generated by the LLM.</p><p><strong>Example Input:</strong></p><p><strong>Example Output:</strong></p>',18)]))}const d=e(n,[["render",l]]),o=JSON.parse('{"path":"/en/api/operators/rare/generate/rarereasondistillgenerator/","title":"RAREReasonDistillGenerator","lang":"en-US","frontmatter":{"title":"RAREReasonDistillGenerator","createTime":"2025/10/09 16:52:48","permalink":"/en/api/operators/rare/generate/rarereasondistillgenerator/"},"readingTime":{"minutes":0.86,"words":257},"git":{"createdTime":1760001305000,"updatedTime":1760001305000,"contributors":[{"name":"Hao Liang","username":"","email":"hao.liang@stu.pku.edu.cn","commits":1,"avatar":"https://gravatar.com/avatar/105bae3e8661728b9f2f5440992b04f5f28459b66a049d09b52213ce1438f6bc?d=retro"}]},"filePathRelative":"en/notes/api/operators/rare/generate/RAREReasonDistillGenerator.md","headers":[]}');export{d as comp,o as data};
